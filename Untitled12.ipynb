{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOY/1cH+OA7087faxZe8k1S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YamnaIsrail/recipe-gpt2-fine-tuning/blob/main/Untitled12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "y2rDk2_EQ8Jb"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        " import pandas as pd\n",
        " import torch\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer, TextDataset, DataCollatorForLanguageModeling, AdamW\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#  Load Pre-trained Model and Tokenizer\n",
        "\n",
        "model_name = \"gpt2\"\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n"
      ],
      "metadata": {
        "id": "siAqoqMVRNSj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Load and Preprocess Data\n",
        "\n",
        "train_path = \"mydata.csv\"  # Update the file name\n",
        "df = pd.read_csv(train_path)\n",
        "texts = df[['Question', 'Islamic Perspective']].apply(lambda x: ' '.join(x), axis=1).tolist()\n",
        "tokenized_texts = [tokenizer.encode(text, return_tensors=\"pt\").squeeze() for text in texts]\n",
        "input_ids = torch.cat(tokenized_texts)\n"
      ],
      "metadata": {
        "id": "WQpKPewmRQKd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Data Collator\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False\n",
        ")\n"
      ],
      "metadata": {
        "id": "x3EoBWE-RTBW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Training Configuration\n",
        "\n",
        "training_args = {\n",
        "    \"output_dir\": \"./recipe_finetuned\",\n",
        "    \"overwrite_output_dir\": True,\n",
        "    \"num_train_epochs\": 1,\n",
        "    \"per_device_train_batch_size\": 4,\n",
        "    \"save_steps\": 10_000,\n",
        "    \"save_total_limit\": 2\n",
        "}\n",
        "# Initialize Optimizer\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5, no_deprecation_warning=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "TTbHM1XSRU60"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import DataCollatorForLanguageModeling"
      ],
      "metadata": {
        "id": "MuLOMav-SVMO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Loop\n",
        "\n",
        "train_dataset = TextDataset(\n",
        "    tokenizer=tokenizer,\n",
        "    file_path=train_path,\n",
        "    block_size=128\n",
        ")\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    collate_fn=data_collator,\n",
        "    batch_size=training_args[\"per_device_train_batch_size\"],\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "for epoch in range(training_args[\"num_train_epochs\"]):\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        input_ids = batch[\"input_ids\"].to(model.device)\n",
        "        labels = batch[\"labels\"].to(model.device)\n",
        "\n",
        "        outputs = model(input_ids, labels=labels)\n",
        "        loss = outputs.loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if step % 1000 == 0:\n",
        "            print(f\"Epoch {epoch}, Step {step}, Loss: {loss.item()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4KzZASLRz4w",
        "outputId": "aabd55dd-7ec5-4b76-cadc-563a87399a4c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Step 0, Loss: 3.3197264671325684\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Save Fine-tuned Model\n",
        "\n",
        "model.save_pretrained(training_args[\"output_dir\"])\n",
        "tokenizer.save_pretrained(training_args[\"output_dir\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qZELheFR4gO",
        "outputId": "212459ca-be9a-4550-bfdc-74de2a00b20f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./recipe_finetuned/tokenizer_config.json',\n",
              " './recipe_finetuned/special_tokens_map.json',\n",
              " './recipe_finetuned/vocab.json',\n",
              " './recipe_finetuned/merges.txt',\n",
              " './recipe_finetuned/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load Fine-tuned Model for Recipe Generation\n",
        "\n",
        "model = GPT2LMHeadModel.from_pretrained(training_args[\"output_dir\"])\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(training_args[\"output_dir\"])\n",
        "\n",
        "# Recipe Generation\n",
        "\n",
        "user_input = input(\"Enter the name of the item for which you want a recipe: \")\n",
        "prompt = f\"Item: {user_input}\\nRecipe:\"\n",
        "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "\n",
        "# Ensure attention_mask is set\n",
        "attention_mask = torch.ones(input_ids.shape, device=model.device)\n",
        "\n",
        "# Set pad_token_id to eos_token_id for open-end generation\n",
        "model.config.pad_token_id = model.config.eos_token_id\n",
        "\n",
        "output = model.generate(input_ids, attention_mask=attention_mask, max_length=200, num_beams=5, no_repeat_ngram_size=2, top_k=50, top_p=0.95)\n",
        "generated_recipe = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "print(f\"\\nGenerated Recipe for {user_input}:\\n{generated_recipe}\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZ-9tKXjR6j5",
        "outputId": "f445d667-c0ea-4d60-a905-e328f1dd95dd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the name of the item for which you want a recipe: 'm struggling to cope with a traumatic experience. How can I heal?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1473: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:386: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generated Recipe for 'm struggling to cope with a traumatic experience. How can I heal?:\n",
            "Item:'m struggling to cope with a traumatic experience. How can I heal?\n",
            "Recipe: http://www.youtube.com/watch?v=X9X-XJ-Y-0A&feature=youtu.be&t=3m33s\n",
            "Ingredients:\n",
            "1/2 cup water\n",
            "3/4 cup granulated sugar\n",
            "2 teaspoons baking powder\n",
            "4 tablespoons unsalted butter, melted\n",
            "Directions: Preheat oven to 350 degrees F. Line a baking sheet with parchment paper. In a large bowl, whisk together the flour, baking soda, and salt. Add the butter mixture to the dry ingredients and mix well. Pour the mixture into the prepared baking dish. Bake for 20-25 minutes, or until a toothpick inserted in the center comes out clean. Remove from the oven and allow to cool completely before serving.\n"
          ]
        }
      ]
    }
  ]
}